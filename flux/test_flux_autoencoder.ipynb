{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode MNIST images as compressed vectors that can later be decoded back into\n",
    "# images.\n",
    "using Flux, Flux.Data.MNIST\n",
    "using Flux: @epochs, onehotbatch, mse, throttle\n",
    "using Base.Iterators: partition\n",
    "using Parameters: @with_kw\n",
    "using CUDAapi\n",
    "if has_cuda()\n",
    "    @info \"CUDA is on\"\n",
    "    import CuArrays\n",
    "    CuArrays.allowscalar(false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Args"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@with_kw mutable struct Args\n",
    "    lr::Float64 = 1e-3  # Learning rate\n",
    "    epochs::Int = 10    # Number of epochs\n",
    "    N::Int = 32         # Size of the encoding\n",
    "    batchsize::Int = 1000  # Batch size for training\n",
    "    sample_len::Int = 20   # Number of random digits in the sample image\n",
    "    throttle::Int = 5      # Throttle timeout\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_processed_data (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_processed_data(args)\n",
    "    # Loading Images\n",
    "    imgs = MNIST.images()\n",
    "    #Converting image of type RGB to float \n",
    "    imgs = channelview.(imgs)\n",
    "    # Partition into batches of size 1000\n",
    "    train_data = [float(hcat(vec.(imgs)...)) for imgs in partition(imgs, args.batchsize)]\n",
    "    \n",
    "    train_data = gpu.(train_data)\n",
    "    return train_data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train(; kws...)\n",
    "    args = Args(; kws...)\n",
    "\n",
    "    train_data = get_processed_data(args)\n",
    "\n",
    "    @info(\"Constructing model......\")\n",
    "    # You can try to make the encoder/decoder network larger\n",
    "    # Also, the output of encoder is a coding of the given input.\n",
    "    # In this case, the input dimension is 28^2 and the output dimension of\n",
    "    # encoder is 32. This implies that the coding is a compressed representation.\n",
    "    # We can make lossy compression via this `encoder`.\n",
    "    encoder = Dense(28^2, args.N, leakyrelu) |> gpu\n",
    "    decoder = Dense(args.N, 28^2, leakyrelu) |> gpu \n",
    "\n",
    "    # Defining main model as a Chain of encoder and decoder models\n",
    "    m = Chain(encoder, decoder)\n",
    "\n",
    "    @info(\"Training model.....\")\n",
    "    loss(x) = mse(m(x), x)\n",
    "    ## Training\n",
    "    evalcb = throttle(() -> @show(loss(train_data[1])), args.throttle)\n",
    "    opt = ADAM(args.lr)\n",
    "    \n",
    "    @epochs args.epochs Flux.train!(loss, params(m), zip(train_data), opt, cb = evalcb)\n",
    "\n",
    "    return m, args\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Images [916415d5-f1e6-5110-898d-aaa5f9f070e0]\n",
      "└ @ Base loading.jl:1260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sample (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Images\n",
    "\n",
    "img(x::Vector) = Gray.(reshape(clamp.(x, 0, 1), 28, 28))\n",
    "\n",
    "function sample(m, args)\n",
    "    imgs = MNIST.images()\n",
    "    #Converting image of type RGB to float \n",
    "    imgs = channelview.(imgs)\n",
    "    # `args.sample_len` random digits\n",
    "    before = [imgs[i] for i in rand(1:length(imgs), args.sample_len)]\n",
    "    # Before and after images\n",
    "    after = img.(map(x -> cpu(m)(float(vec(x))), before))\n",
    "    # Stack them all together\n",
    "    hcat(vcat.(before, after)...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Constructing model......\n",
      "└ @ Main In[4]:6\n",
      "┌ Info: Training model.....\n",
      "└ @ Main In[4]:18\n",
      "┌ Info: Epoch 1\n",
      "└ @ Main /Users/yasu/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(train_data[1]) = 0.10221675f0\n",
      "loss(train_data[1]) = 0.048363827f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 2\n",
      "└ @ Main /Users/yasu/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(train_data[1]) = 0.03140944f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 3\n",
      "└ @ Main /Users/yasu/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(train_data[1]) = 0.02301975f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 4\n",
      "└ @ Main /Users/yasu/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(train_data[1]) = 0.019030891f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 5\n",
      "└ @ Main /Users/yasu/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(train_data[1]) = 0.016889704f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 6\n",
      "└ @ Main /Users/yasu/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(train_data[1]) = 0.015487493f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 7\n",
      "└ @ Main /Users/yasu/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(train_data[1]) = 0.014464614f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 8\n",
      "└ @ Main /Users/yasu/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(train_data[1]) = 0.013701256f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 9\n",
      "└ @ Main /Users/yasu/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(train_data[1]) = 0.01316015f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 10\n",
      "└ @ Main /Users/yasu/.julia/packages/Flux/Fj3bt/src/optimise/train.jl:121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(train_data[1]) = 0.012733687f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Saving image sample as sample_ae.png\n",
      "└ @ Main In[6]:4\n",
      "┌ Info: Precompiling PNGFiles [f57f5aa1-a3ce-4bc8-8ab9-96f992907883]\n",
      "└ @ Base loading.jl:1260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd(@__DIR__)\n",
    "m, args= train()\n",
    "# Sample output\n",
    "@info(\"Saving image sample as sample_ae.png\")\n",
    "save(\"test_flux_autoencoder.png\", sample(m, args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img(x::Vector) = Gray.(reshape(clamp.(x, 0, 1), 28, 28))\n",
    "\n",
    "function sample_encoder(m, args)\n",
    "    imgs = MNIST.images()\n",
    "    #Converting image of type RGB to float \n",
    "    imgs = channelview.(imgs)\n",
    "    # `args.sample_len` random digits\n",
    "    before = [imgs[i] for i in rand(1:length(imgs), args.sample_len)]\n",
    "    # Before and after images\n",
    "    after = img.(map(x -> cpu(m(1))(float(vec(x))), before))\n",
    "    # Stack them all together\n",
    "    hcat(vcat.(before, after)...)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
